{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Movie Recommender"
      ],
      "metadata": {
        "id": "83JVv_zAWBWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "*Make sure to **make a copy** of this notebook and to work from there (File --> Save a Copy in Drive).*\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Hi! This notebook will help you build recommendations for movies by applying \n",
        "NLP to the movie descriptions. Run the code blocks one by one by clicking the Run symbol or by pressing **Shift + Enter**. \n",
        "\n",
        "# Getting started!\n",
        "\n",
        "We're first going to import some packages, such that we read & process the data."
      ],
      "metadata": {
        "id": "hbbfNjccZ_WP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orKUX1DGsLp8"
      },
      "outputs": [],
      "source": [
        "# Download the W2V model\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")\n",
        "\n",
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Make sure we can see all columns in this notebook\n",
        "pd.set_option(\"display.max_colwidth\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data from this github. Ignore lines that can't be parsed\n",
        "df_complete = pd.read_csv(r\"https://raw.githubusercontent.com/enniasuijkerbuijk/bb-nlp-case/main/data/movies.csv\", on_bad_lines=\"skip\")"
      ],
      "metadata": {
        "id": "tISqsa7hWQmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This server is a bit slow, so sample movies\n",
        "df = df_complete.sample(n=5_000, random_state=5)\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "9-4sASJBWgxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the data\n",
        "df.head()"
      ],
      "metadata": {
        "id": "a56jKVQOab_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data processing/cleaning"
      ],
      "metadata": {
        "id": "TJpRI-4sXibB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preprocessing\n",
        "df[\"description_clean\"] = df[\"description\"].astype(str)\n",
        "\n",
        "# Drop rows where the description isn't filled in correctly\n",
        "df = df[df[\"description_clean\"] != \"\"]\n",
        "df = df[df[\"description_clean\"].notnull()]\n",
        "df = df[df[\"description_clean\"] != \"\"]\n",
        "df = df[df[\"description_clean\"].notnull()]"
      ],
      "metadata": {
        "id": "jja5KOIISXPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: What cleaning steps you would like to do? \n",
        "..."
      ],
      "metadata": {
        "id": "lsywYBCFWwdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a movie for which you want the recommendation \n",
        "index = 2342 #TODO fill in a number here\n",
        "df.iloc[index:index+1,]"
      ],
      "metadata": {
        "id": "xTdqX46_a6A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP Modelling"
      ],
      "metadata": {
        "id": "XnUOuFqCXmYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get W2V embedding - Takes about 2 minutes on the sampled dataset for 5K rows\n",
        "model = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Construct the embeddings using the model\n",
        "df[\"embedding\"] = df['description_clean'].apply(lambda x:model(x).vector)\n",
        "\n",
        "# Drop any rows without embeddings\n",
        "df = df[~df[\"embedding\"].isna()]\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QlpooMSCQ_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "def cosine_similarity(a,b):\n",
        "    \"\"\"\n",
        "    Get cosine similarity between two arrays a,b\n",
        "    :param a: array one\n",
        "    :param b: array two\n",
        "    \"\"\"\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "\n",
        "def get_closest(df, ix):\n",
        "    \"\"\"\n",
        "    Get most similar movie based on the index given \n",
        "    :param df: movies dataframe, including the embeddings\n",
        "    :param ix: Index of the movie you're interested in \n",
        "    \"\"\"\n",
        "    base_embed = df.at[ix, \"embedding\"]\n",
        "    print(f\"Find closest movie for \\nTitle:{df.at[ix, 'title']}: \\nOverwiew: {df.at[ix, 'description']}\")\n",
        "    \n",
        "    for i in df.index:\n",
        "        this_embed = df.at[i, \"embedding\"]\n",
        "        try:\n",
        "          df.at[i, \"similarity\"] = cosine_similarity(base_embed, this_embed)\n",
        "        except:\n",
        "          print(df[df.index == i])\n",
        "        \n",
        "    \n",
        "    return df[df[\"similarity\"].notnull()].sort_values(\"similarity\", ascending=False)[[\"title\", \"description\", \"similarity\"]]"
      ],
      "metadata": {
        "id": "NAVl1OtPRHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use get_closest to get movie that is most similar to my little pony\n",
        "get_closest(df, index)"
      ],
      "metadata": {
        "id": "gZCzaaMMUPVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improvements\n",
        "You've now found recommendations for your chosen movie, congratuations! \n",
        "\n",
        "Are the recommendations good? Do you have ideas on tweaks or methods you could implement to improve the recommendations?"
      ],
      "metadata": {
        "id": "YuqpZAn9bbrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Improve the recommendations\n",
        "..."
      ],
      "metadata": {
        "id": "X322ooffbiD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}