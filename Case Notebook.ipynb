{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/enniasuijkerbuijk/bb-nlp-case/blob/main/Case%20Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to **make a copy** of this notebook and to work from there (*File --> Save a Copy in Drive*).\n",
        "\n",
        "\n",
        "This notebook will take you through the case. Run the code blocks one by one by clicking the Run symbol or by pressing **Shift + Enter**. \n",
        "\n",
        "# Getting started!"
      ],
      "metadata": {
        "id": "hbbfNjccZ_WP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orKUX1DGsLp8"
      },
      "outputs": [],
      "source": [
        "# Download the W2V model\n",
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data\n",
        "import pandas as pd\n",
        "\n",
        "# Make sure we can see all columns in this notebook\n",
        "pd.set_option(\"display.max_colwidth\", 999)\n",
        "pd.set_option(\"display.max_columns\", 999)\n",
        "\n",
        "# Read the data from this github. Ignore lines that can't be parsed\n",
        "df = pd.read_csv(r\"https://raw.githubusercontent.com/maartenvanhooft/avans-nlp/main/movies.csv\", on_bad_lines=\"skip\")\n",
        "\n",
        "# This server is a bit slow, so sample movies\n",
        "df = df.sample(n=5_000, random_state=5)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Data preprocessing\n",
        "df[\"overview_clean\"] = df[\"overview\"].astype(str)\n",
        "\n",
        "# TODO: What cleaning steps you would like to do? \n",
        "...\n",
        "\n",
        "# Remove empty overviews and titles\n",
        "df = df[df[\"overview_clean\"] != \"\"]\n",
        "df = df[df[\"overview_clean\"].notnull()]\n",
        "df = df[df[\"title\"] != \"\"]\n",
        "df = df[df[\"title\"].notnull()]\n",
        "\n",
        "# We want a recommendation for this movie:\n",
        "df[df[\"title\"].str.contains(\"my little pony\")]"
      ],
      "metadata": {
        "id": "jja5KOIISXPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get W2V embedding - Takes about 2 minutes on the sampled dataset for 5K rows\n",
        "model = spacy.load('en_core_web_sm')\n",
        "\n",
        "# TODO: Construct the embeddings using the model\n",
        "df[\"embedding\"] = ... \n",
        "\n",
        "# If we don't have embeddings, drop the row\n",
        "df = df[~df[\"embedding\"].isna()]\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "QlpooMSCQ_OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "\n",
        "def cosine_similarity(a,b):\n",
        "    \"\"\"\n",
        "    Get cosine similarity between two arrays a,b\n",
        "    :param a: array one\n",
        "    :param b: array two\n",
        "    \"\"\"\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "\n",
        "def get_closest(df, ix):\n",
        "    \"\"\"\n",
        "    Get most similar movie based on the index given \n",
        "    :param df: movies dataframe, including the embeddings\n",
        "    :param ix: Index of the movie you're interested in \n",
        "    \"\"\"\n",
        "    base_embed = df.at[ix, \"embedding\"]\n",
        "    print(f\"Find closest movie for \\nTitle:{df.at[ix, 'title']}: \\nOverwiew: {df.at[ix, 'overview']}\")\n",
        "    \n",
        "    for i in df.index:\n",
        "        this_embed = df.at[i, \"embedding\"]\n",
        "        try:\n",
        "          df.at[i, \"similarity\"] = cosine_similarity(base_embed, this_embed)\n",
        "        except:\n",
        "          print(df[df.index == i])\n",
        "        \n",
        "    \n",
        "    return df[df[\"similarity\"].notnull()].sort_values(\"similarity\", ascending=False)[[\"title\", \"overview\", \"similarity\"]]"
      ],
      "metadata": {
        "id": "NAVl1OtPRHFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Use get_closest to get movie that is most similar to my little pony\n"
      ],
      "metadata": {
        "id": "gZCzaaMMUPVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you've got time left, try to see if you can improve the recommendations by using other data in the movies dataframe (df)"
      ],
      "metadata": {
        "id": "YuqpZAn9bbrC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X322ooffbiD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}